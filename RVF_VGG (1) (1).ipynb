{"cells":[{"cell_type":"markdown","metadata":{"id":"b9VtlpWQ5T0G"},"source":["## Download the data from Kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pj5xLFkiB1fe"},"outputs":[],"source":["!rm -rf real_and_fake_face real_and_fake_face_detection processed"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zPbushF5T0H","outputId":"4d9c175f-f18a-4ec9-b55a-b2669022539e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"," mkdir: cannot create directory ‘/root/.kaggle’: File exists\n","\n"," \n"," \n","real-and-fake-face-detection.zip: Skipping, found more recently modified local copy (use --force to force download)\n"]}],"source":["from google.colab import drive\n","from subprocess import Popen, PIPE\n","# makes files from your drive accessible\n","drive.mount('/content/drive', force_remount=True)\n","\n","# TODO - specify path to your API key via google drive\n","api_key_filepath = \"/content/drive/MyDrive/MDST/RvF/kaggle.json\"\n","\n","\n","# Kaggle API Key setup ------------------\n","cmd = \"mkdir /root/.kaggle\"\n","process = Popen(cmd.split(), stdout=PIPE, stderr=PIPE)\n","stdout, stderr = process.communicate()\n","print(stdout.decode(\"utf-8\"), stderr.decode(\"utf-8\"))\n","cmd = f\"cp -f {api_key_filepath} /root/.kaggle/\"\n","process = Popen(cmd.split(), stdout=PIPE, stderr=PIPE)\n","stdout, stderr = process.communicate()\n","print(stdout.decode(\"utf-8\"), stderr.decode(\"utf-8\"))\n","cmd = f\"chmod 600 /root/.kaggle/kaggle.json\"\n","process = Popen(cmd.split(), stdout=PIPE, stderr=PIPE)\n","print(stdout.decode(\"utf-8\"), stderr.decode(\"utf-8\"))\n","# ------------------------------\n","!kaggle datasets download -d ciplab/real-and-fake-face-detection\n","!unzip -q real-and-fake-face-detection.zip"]},{"cell_type":"markdown","source":[],"metadata":{"id":"eV0i5R1pSIAB"}},{"cell_type":"markdown","metadata":{"id":"NedqO4P_5T0I"},"source":["# Setup PyTorch Data Loading\n","\n","The code in the next cell can be copied into your notebook to load the downloaded data correctly. It does two things:\n","- processes the dataset into a train and test set\n","- creates data loaders for the training and testing data\n","\n","Don't worry about the details, but if you're on the dataset team, you'll want to read carefully through this part to understand how the code works (since you'll be editing this to make your own version of the dataset!)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jIoPLbUb62gZ"},"outputs":[],"source":["from imageio.v3 import imread\n","import pandas as pd\n","from pathlib import Path\n","from random import random\n","from shutil import copy\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import functional\n","\n","class RealAndFakeFaceProcessor:\n","    def __init__(self, directory, train_test_split = 0.7) -> None:\n","        self.train_test_split = train_test_split\n","\n","        self.train_index = 0\n","        self.test_index = 0\n","\n","        self.src_directory = Path(directory)\n","        self.directory = self.src_directory.parent / \"processed\"\n","\n","        self.tgt_train = self.directory / \"train\"\n","        self.tgt_train.mkdir(parents=True, exist_ok=True)\n","\n","        self.tgt_test = self.directory / \"test\"\n","        self.tgt_test.mkdir(parents=True, exist_ok=True)\n","\n","        self.index_by_type = {\"index\":[], \"partition\": [], \"type\": [], \"label\": []}\n","        self.__process(\"training_fake\",\"easy\")\n","        self.__process(\"training_fake\",\"mid\")\n","        self.__process(\"training_fake\",\"hard\")\n","        self.__process(\"training_real\",\"real\")\n","\n","        df = pd.DataFrame(self.index_by_type)\n","        df.to_csv(self.directory / \"images.csv\", index=False)\n","\n","\n","    def __add_image_to_record(self, index: int, partition: str, type: str, label: int):\n","        \"\"\"Real - label is 1, Fake - label is 0\"\"\"\n","        self.index_by_type[\"index\"].append(index)\n","        self.index_by_type[\"partition\"].append(partition)\n","        self.index_by_type[\"type\"].append(type)\n","        self.index_by_type[\"label\"].append(label)\n","\n","\n","    def __process(self, subdir: str, type: str) -> None:\n","        src = self.src_directory / subdir\n","        label = 1 if type == \"real\" else 0\n","\n","        for image in src.iterdir():\n","            if image.name.startswith(type):\n","                random_number = random()\n","                if random() > self.train_test_split:\n","                    copy(image.absolute(), self.tgt_test / f\"{self.test_index}.png\")\n","                    self.__add_image_to_record(self.test_index, \"test\", type, label)\n","                    self.test_index += 1\n","                else:\n","                    copy(image.absolute(), self.tgt_train / f\"{self.train_index}.png\")\n","                    self.__add_image_to_record(self.train_index, \"train\", type, label)\n","                    self.train_index += 1\n","\n","class RealAndFakeFaceDataset(Dataset):\n","    def __init__(\n","        self,\n","        directory: str,\n","        partition: str =\"train\"\n","    ) -> 'RealAndFakeFaceDataset':\n","        self.partition = partition\n","        if partition not in (\"train\", \"test\"):\n","            raise ValueError(f\"Invalid partition specified - {partition}\")\n","        self.directory = Path(directory)\n","        self.img_directory = self.directory / partition\n","        metadata = pd.read_csv(self.directory / \"images.csv\")\n","        self.metadata = metadata[metadata[\"partition\"] == self.partition]\n","\n","    def __len__(self) -> int:\n","        return len(self.metadata)\n","\n","    def __getitem__(self, index: int) -> tuple[torch.tensor, int]:\n","        filename = self.img_directory / f\"{index}.png\"\n","        label = self.metadata.iloc[index][\"label\"]\n","\n","        image = torch.from_numpy(imread(filename))\n","        image = image.to(torch.float32)\n","        image = image.permute((2,0,1))\n","        image = functional.resize(image, (224, 224), antialias=True)\n","        image /= 255.0\n","\n","        image_mean = [.485, .456, .406]\n","        image_std = [.229, .224, .225]\n","\n","        preprocess = transforms.Compose([\n","            transforms.Normalize(mean = image_mean, std = image_std),\n","            transforms.RandomCrop((200,200)),\n","            transforms.RandomRotation((-15,15), expand=False)\n","        ])\n","        image = preprocess(image)\n","\n","        return image, label\n","\n","    def get_type(self, index) -> str:\n","        return self.metadata.iloc[index][\"type\"]\n","\n","processor = RealAndFakeFaceProcessor(\"real_and_fake_face\") # Call this to process the dataset into a train and test set\n","train = RealAndFakeFaceDataset(\"processed\", \"train\")\n","test = RealAndFakeFaceDataset(\"processed\", \"test\")\n","\n","train_loader = DataLoader(train, batch_size = 32, shuffle=True)\n","test_loader = DataLoader(test, batch_size = 32)"]},{"cell_type":"code","source":[],"metadata":{"id":"ctajG5n4Tv4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qS2Zi1FJAtJ"},"outputs":[],"source":["from tqdm import tqdm\n","import torch\n","\n","from torchvision import models, transforms, datasets\n","import torch\n","\n","source_model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n","source_model = source_model.cuda()\n","feats_list = list(source_model.features)\n","new_feats_list = []\n","\n","# modify convolution layers\n","# source_model.features = nn.Sequential(*new_feats_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mplVlUV-entZ","outputId":"84850fa0-49ad-4c6d-817c-dc55fd214ee6"},"outputs":[{"output_type":"stream","name":"stdout","text":["VGG-16 has 138357544 parameters\n"]}],"source":["count = 0\n","for param in source_model.parameters():\n","    count += param.numel()\n","print(f\"VGG-16 has {count} parameters\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlwGiO0veszd","outputId":"88ec641f-c318-44a5-9de3-311f12a14192"},"outputs":[{"output_type":"stream","name":"stdout","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"]}],"source":["print(source_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lniu58JDf3nw"},"outputs":[],"source":["source_model.classifier = torch.nn.Sequential(\n","    torch.nn.Linear(25088, 1024),\n","    torch.nn.ReLU(),\n","    torch.nn.Dropout(0.7),\n","    torch.nn.Linear(1024, 128),\n","    torch.nn.ReLU(),\n","    torch.nn.Dropout(0.7),\n","    torch.nn.Linear(128, 2)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zLdpe6Ff83r","outputId":"276524e2-b4e3-4fc5-ab2b-1f1a1e43c25e"},"outputs":[{"output_type":"stream","name":"stdout","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=1024, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.7, inplace=False)\n","    (3): Linear(in_features=1024, out_features=128, bias=True)\n","    (4): ReLU()\n","    (5): Dropout(p=0.7, inplace=False)\n","    (6): Linear(in_features=128, out_features=2, bias=True)\n","  )\n",")\n"]}],"source":["print(source_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16CdRpT_gFaU"},"outputs":[],"source":["for parameter in source_model.features.parameters():\n","    parameter.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qMX_H8o2ode"},"outputs":[],"source":["from typing import Callable\n","from torch import nn\n","from torch.utils.data import DataLoader\n","\n","def evaluate(model: nn.Module, criterion: Callable, loader: DataLoader, device='cuda') -> tuple[float]:\n","    model.eval()\n","    with torch.no_grad():\n","        correct, total = 0,0\n","        loss = 0.0\n","        for i, (X, y) in enumerate(loader):\n","            outputs = model(X.to(device)).to('cpu')\n","            loss += criterion(outputs, y).item()\n","            _, predicted = torch.max(outputs.data, 1) # get predicted class\n","            total += len(y)\n","            correct += (predicted == y).sum().item()\n","    model.train()\n","    return correct / total, loss / total"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zd9ihYs4yucV","outputId":"25ed155f-5576-4b4d-bb59-53aa5a60eb6f"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:22<00:00,  2.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Loss - (Train 0.02171/Test 0.02, Accuracy - (Train 0.52675/Test 0.54)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:22<00:00,  2.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: Loss - (Train 0.02171/Test 0.02, Accuracy - (Train 0.59602/Test 0.63)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:21<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: Loss - (Train 0.02155/Test 0.02, Accuracy - (Train 0.61043/Test 0.58)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:22<00:00,  2.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: Loss - (Train 0.02152/Test 0.02, Accuracy - (Train 0.60974/Test 0.59)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:23<00:00,  1.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: Loss - (Train 0.02131/Test 0.02, Accuracy - (Train 0.63855/Test 0.60)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:23<00:00,  1.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: Loss - (Train 0.02114/Test 0.02, Accuracy - (Train 0.56996/Test 0.55)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:22<00:00,  2.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: Loss - (Train 0.02111/Test 0.02, Accuracy - (Train 0.64746/Test 0.62)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:22<00:00,  2.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8: Loss - (Train 0.02061/Test 0.02, Accuracy - (Train 0.61180/Test 0.60)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:22<00:00,  2.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: Loss - (Train 0.02084/Test 0.02, Accuracy - (Train 0.63786/Test 0.63)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:23<00:00,  1.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Loss - (Train 0.02057/Test 0.02, Accuracy - (Train 0.59122/Test 0.59)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:22<00:00,  2.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: Loss - (Train 0.02081/Test 0.02, Accuracy - (Train 0.63374/Test 0.62)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46/46 [00:22<00:00,  2.01it/s]\n"]}],"source":["from tqdm import tqdm\n","\n","device ='cuda' if torch.cuda.is_available() else 'cpu' # automatically use gpu if available\n","epochs = 30  # Change Number of epochs\n","train_losses, train_accuracies = [], []\n","test_losses, test_accuracies = [], []\n","model =  source_model.to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=source_model.parameters(), lr=1e-3)\n","\n","for epoch in range(epochs):\n","    source_model.train()\n","    for i, (X, y) in enumerate(tqdm(train_loader)):\n","        X, y = X.to(device), y.to(device)\n","        optimizer.zero_grad()\n","        outputs = source_model(X)\n","        loss = criterion(outputs, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","    train_accuracy, train_loss = evaluate(source_model, criterion, train_loader, device)\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","\n","    test_accuracy, test_loss = evaluate(source_model, criterion, test_loader, device)\n","    test_losses.append(test_loss)\n","    test_accuracies.append(test_accuracy)\n","\n","    print(\n","        f\"Epoch {epoch + 1}: Loss - (Train {train_loss:.5f}/Test {test_loss:.2f}, \"\n","        f\"Accuracy - (Train {train_accuracy:.5f}/Test {test_accuracy:.2f})\"\n","    )"]},{"cell_type":"code","source":[],"metadata":{"id":"Lwzx9pZqULiX"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}